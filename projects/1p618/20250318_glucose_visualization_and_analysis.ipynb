{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e919c4-7609-4fad-9f6a-d2a2dd8cfb91",
   "metadata": {
    "id": "d7e919c4-7609-4fad-9f6a-d2a2dd8cfb91"
   },
   "source": [
    "# Glucose analysis\n",
    "\n",
    "* Analysis of continuous glucose monitor data.\n",
    "* Use `diametrics` python package for analysis (install from source)\n",
    "\n",
    "\n",
    "#### group assignments\n",
    "\n",
    "* Athlete\n",
    "    - M001\n",
    "    - M002\n",
    "    - MPS005\n",
    "    - MPS006\n",
    "    - MPS007\n",
    "    - MPS009\n",
    "* Control\n",
    "    - MPS008\n",
    "\n",
    "  \n",
    "\n",
    "## 1 preprocess data for continuous glucose monitors (CGMs)\n",
    "\n",
    "* load the datafiles\n",
    "    - data are stored in directory `raw_data/cgm_data/`\n",
    "* extract the relevant windows\n",
    "    * workout\n",
    "        * workout_start\n",
    "        * workout_end\n",
    "    * up to 7 days after workout\n",
    "* extract the features\n",
    "    * Mean amplitude of glycemic excursions (MAGE)\n",
    "    * LBGI\n",
    "    * HBGI\n",
    "    * Mean average glucose (`mean_avg_glc`)\n",
    "\n",
    "      \n",
    "## 2 plot glucose curves during workout and during day of workout (12am of day of workout until `workout_end + 24 hours`)\n",
    "\n",
    "* use the `workout_start` and `workout_end` timestamps\n",
    "* use white background for the workout time window\n",
    "* use blue background for 10pm to 6am\n",
    "* use light grey background for other times\n",
    "\n",
    "\n",
    "## 3 Regression model\n",
    "\n",
    "* regression of glucose features ~ proteomics proteins\n",
    "    * MAGE ~ proteins\n",
    "    * mean_avg_glc ~ proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oEsATy8hzTv_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20239,
     "status": "ok",
     "timestamp": 1742344479860,
     "user": {
      "displayName": "Kirk Gosik",
      "userId": "00298791141274615447"
     },
     "user_tz": 240
    },
    "id": "oEsATy8hzTv_",
    "outputId": "db71b7c4-2089-4509-ed88-2a2aa7ed375f"
   },
   "outputs": [],
   "source": [
    "# prompt: connect to google drive code\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Bquhc31Dzlp0",
   "metadata": {
    "id": "Bquhc31Dzlp0"
   },
   "outputs": [],
   "source": [
    "project_path = '/content/drive/MyDrive/projects/glucose-data-science'\n",
    "data_path = f'{project_path}/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XbAoIk0aJnZJ",
   "metadata": {
    "id": "XbAoIk0aJnZJ"
   },
   "outputs": [],
   "source": [
    "!cp -r /content/drive/MyDrive/projects/glucose-data-science/notebook/utils.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9416e5-fdd4-4c18-9879-a8180bbd4963",
   "metadata": {
    "id": "da9416e5-fdd4-4c18-9879-a8180bbd4963"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ys7MtluoJ7QY",
   "metadata": {
    "id": "ys7MtluoJ7QY"
   },
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qMJLMJEZJ7bV",
   "metadata": {
    "id": "qMJLMJEZJ7bV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9ebe713-cff9-4a4d-a494-ded5592203d7",
   "metadata": {
    "id": "d9ebe713-cff9-4a4d-a494-ded5592203d7"
   },
   "source": [
    "## 1 preprocess data for continuous glucose monitors (CGMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i9Q0lUi44Xl5",
   "metadata": {
    "id": "i9Q0lUi44Xl5"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(file_name):\n",
    "  \"\"\"\n",
    "  Parameters\n",
    "  ----------\n",
    "  file_name: str -\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  pd.DataFrame -\n",
    "  \"\"\"\n",
    "  df = pd.read_csv(file_name)\n",
    "  df['file_name'] = file_name\n",
    "  df['timestamp'] = pd.to_datetime(df['Timestamp (YYYY-MM-DDThh:mm:ss)'])\n",
    "  df['duration'] = pd.to_datetime(df['Duration (hh:mm:ss)'])\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab87352d-93ff-49f3-8200-7977203da723",
   "metadata": {
    "id": "ab87352d-93ff-49f3-8200-7977203da723"
   },
   "source": [
    "### load demographic metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_2r7GkGl0FzX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 419,
     "status": "ok",
     "timestamp": 1742345383522,
     "user": {
      "displayName": "Kirk Gosik",
      "userId": "00298791141274615447"
     },
     "user_tz": 240
    },
    "id": "_2r7GkGl0FzX",
    "outputId": "18610726-eb8d-41d8-d8ec-5ce3b1b14e02"
   },
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "for f in os.listdir(data_path):\n",
    "  d = pd.read_csv(f'{data_path}/{f}')\n",
    "  d['file_name'] = f\n",
    "  d['timestamp'] = pd.to_datetime(d['Timestamp (YYYY-MM-DDThh:mm:ss)'])\n",
    "  d['duration'] = pd.to_datetime(d['Duration (hh:mm:ss)'])\n",
    "  df_list.append(d)\n",
    "\n",
    "len(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9FuP2uE1Oz7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 843
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1742345410660,
     "user": {
      "displayName": "Kirk Gosik",
      "userId": "00298791141274615447"
     },
     "user_tz": 240
    },
    "id": "f9FuP2uE1Oz7",
    "outputId": "959d9bb0-12da-4252-8c94-ef307539b39c"
   },
   "outputs": [],
   "source": [
    "df = pd.concat(df_list)\n",
    "df.head()\n",
    "df.dropna(subset=['Duration (hh:mm:ss)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o5Hba_ql1cjn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 85,
     "status": "ok",
     "timestamp": 1742345144846,
     "user": {
      "displayName": "Kirk Gosik",
      "userId": "00298791141274615447"
     },
     "user_tz": 240
    },
    "id": "o5Hba_ql1cjn",
    "outputId": "170f8640-18f0-4a66-cddc-c9676e056692"
   },
   "outputs": [],
   "source": [
    "df[['Duration (hh:mm:ss)']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wHCi0Zxc1Zyv",
   "metadata": {
    "id": "wHCi0Zxc1Zyv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd69161-61e9-46a3-aa1b-7a7268dfbace",
   "metadata": {
    "id": "9bd69161-61e9-46a3-aa1b-7a7268dfbace"
   },
   "outputs": [],
   "source": [
    "link_to_demographic_metadata = f'{project_path}/raw_data/demographic_metadata.csv'\n",
    "df_metadata = pd.read_csv(link_to_demographic_metadata)\n",
    "\n",
    "date_format = '%m/%d/%Y %I:%M:%S %p'\n",
    "df_metadata['workout_start'] = pd.to_datetime(df_metadata['window_start'], format=date_format)\n",
    "df_metadata['workout_end'] = pd.to_datetime(df_metadata['window_end'], format=date_format)\n",
    "df_metadata['R-1'] = pd.to_datetime(df_metadata['R-1'], format=date_format)\n",
    "df_metadata['R'] = pd.to_datetime(df_metadata['R'], format=date_format)\n",
    "df_metadata['R+1'] = pd.to_datetime(df_metadata['R+1'], format=date_format)\n",
    "df_metadata['R+7'] = pd.to_datetime(df_metadata['R+7'], format=date_format, errors='coerce')\n",
    "\n",
    "df_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12e108b-17b9-4af3-ae86-c0013635640b",
   "metadata": {
    "id": "b12e108b-17b9-4af3-ae86-c0013635640b"
   },
   "source": [
    "## load the raw data from `raw_data/cgm_data` using `diametrics` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9c764c-1804-41cc-84f1-036e2b82607e",
   "metadata": {
    "id": "1c9c764c-1804-41cc-84f1-036e2b82607e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e0e1948-e0a9-4c52-8390-ba0c774e8660",
   "metadata": {
    "id": "1e0e1948-e0a9-4c52-8390-ba0c774e8660"
   },
   "source": [
    "## extract relevant windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694018f7-e8fe-420e-a54e-737b8c3e5422",
   "metadata": {
    "id": "694018f7-e8fe-420e-a54e-737b8c3e5422"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "191f5e0d-a95d-44b9-a4ed-1bcfaeb75f13",
   "metadata": {
    "id": "191f5e0d-a95d-44b9-a4ed-1bcfaeb75f13"
   },
   "source": [
    "## extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233adf08-8457-4d14-bd7d-40667ce02ea4",
   "metadata": {
    "id": "233adf08-8457-4d14-bd7d-40667ce02ea4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca9b8ce-5c49-4f87-a2bc-d3178cc3ccb0",
   "metadata": {
    "id": "eca9b8ce-5c49-4f87-a2bc-d3178cc3ccb0",
    "outputId": "534c217c-58cf-451c-829a-a75adfc09498"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1. LOAD DEMOGRAPHIC METADATA\n",
    "# ------------------------------------------------------------------------------\n",
    "metadata_path = r'../../../proteomics_data_analysis_task/raw_data/demographic_metadata.csv'\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "\n",
    "# Convert relevant columns to datetime\n",
    "time_cols = ['workout_start', 'workout_end', 'R-1', 'R', 'R+1', 'R+7']\n",
    "for col in time_cols:\n",
    "    metadata_df[col] = pd.to_datetime(metadata_df[col])\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 2. LOAD ALL CGM FILES, EXTRACT SUBJECT ID FROM CELL A2, THEN READ THE DATA\n",
    "# ---------------------------------------------------------------------------\n",
    "cgm_folder = r'../../../proteomics_data_analysis_task/raw_data/cgm_data'\n",
    "# Find all .csv files like M001.csv, MPS005.csv, etc.\n",
    "cgm_files = glob.glob(os.path.join(cgm_folder, '*.csv'))\n",
    "\n",
    "cgm_data_dict = {}  # Key = user_id (e.g., \"M001\"), Value = DataFrame of CGM data\n",
    "\n",
    "for file_path in cgm_files:\n",
    "    # Extract the user ID from the filename: \"M001.csv\" -> \"M001\"\n",
    "    base_name = os.path.basename(file_path)     # \"M001.csv\"\n",
    "    user_id   = os.path.splitext(base_name)[0]  # \"M001\"\n",
    "\n",
    "    # Read the CSV, skipping the first two lines so that\n",
    "    # the 3rd line is recognized as column headers\n",
    "    df = pd.read_csv(file_path, skiprows=2)\n",
    "\n",
    "    # Typical columns might be:\n",
    "    # \"Device\", \"Serial Number\", \"Device Timestamp\", \"Record Type\",\n",
    "    # \"Historic Glucose mg/dL\", \"Scan Glucose mg/dL\"\n",
    "    # Adjust names as needed:\n",
    "    df.rename(\n",
    "        columns={\n",
    "            'Device Timestamp': 'time',\n",
    "            'Historic Glucose mg/dL': 'glc_hist',\n",
    "            'Scan Glucose mg/dL': 'glc_scan'\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    # Convert 'time' to datetime\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "    # Optionally combine historic + scan glucose into a single 'glc' column\n",
    "    df['glc'] = df['glc_hist'].combine_first(df['glc_scan'])\n",
    "\n",
    "    # Keep only the columns you need (time and glc)\n",
    "    df = df[['time', 'glc']].dropna(subset=['glc']).sort_values('time').reset_index(drop=True)\n",
    "\n",
    "    # Store in our dictionary using the user_id\n",
    "    cgm_data_dict[user_id] = df\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3. FOR EACH SUBJECT IN METADATA: FILTER CGM DATA AND PLOT WINDOWS\n",
    "# ---------------------------------------------------------------------------\n",
    "for idx, meta_row in metadata_df.iterrows():\n",
    "    sub_id = meta_row['subject_id']  # e.g., \"M001\" or \"MPS005\"\n",
    "    group  = meta_row.get('group', '')  # If you have a 'group' column\n",
    "\n",
    "    # Check if we have CGM data for this subject ID\n",
    "    if sub_id not in cgm_data_dict:\n",
    "        print(f\"No CGM data found for subject {sub_id}\")\n",
    "        continue\n",
    "\n",
    "    # Retrieve CGM data from our dictionary\n",
    "    subject_df = cgm_data_dict[sub_id].copy()\n",
    "\n",
    "    # Extract relevant timestamps (R-1, R, R+1, R+7)\n",
    "    t_r_minus_1 = meta_row.get('R-1', None)\n",
    "    t_r         = meta_row.get('R',   None)\n",
    "    t_r_plus_1  = meta_row.get('R+1', None)\n",
    "    t_r_plus_7  = meta_row.get('R+7', None)\n",
    "\n",
    "    # Create a multi-subplot figure to illustrate each window\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.suptitle(f'Glucose Levels for {sub_id} (Group: {group})', fontsize=14)\n",
    "\n",
    "    def plot_window(ax, start_time, end_time, label):\n",
    "        # Filter subject_df by the given time window\n",
    "        if pd.notnull(start_time) and pd.notnull(end_time):\n",
    "            mask = (subject_df['time'] >= start_time) & (subject_df['time'] <= end_time)\n",
    "            window_df = subject_df.loc[mask]\n",
    "\n",
    "            ax.plot(window_df['time'], window_df['glc'], marker='o', label=label)\n",
    "            ax.set_title(label)\n",
    "            ax.set_xlabel('Time')\n",
    "            ax.set_ylabel('Glucose (mg/dL)')\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "            ax.legend()\n",
    "\n",
    "    # Subplot 1: R-1 to R\n",
    "    ax1 = plt.subplot(2, 2, 1)\n",
    "    plot_window(ax1, t_r_minus_1, t_r, 'R-1 → R')\n",
    "\n",
    "    # Subplot 2: R to R+1\n",
    "    ax2 = plt.subplot(2, 2, 2)\n",
    "    plot_window(ax2, t_r, t_r_plus_1, 'R → R+1')\n",
    "\n",
    "    # Subplot 3: R to R+7\n",
    "    ax3 = plt.subplot(2, 2, 3)\n",
    "    plot_window(ax3, t_r, t_r_plus_7, 'R → R+7')\n",
    "\n",
    "    # Adjust layout and show\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # Or save each subject's figure:\n",
    "    # plt.savefig(f'{sub_id}_glucose_windows.png', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9145d7ea",
   "metadata": {
    "id": "9145d7ea",
    "outputId": "c3bf71f6-9693-41a0-9ea5-73b2274cbc65"
   },
   "outputs": [],
   "source": [
    "#####\n",
    "# Concatenate glucose data vertically\n",
    "#####\n",
    "\n",
    "# Assuming `cgm_data_dict` is defined\n",
    "# Create an empty list to store dataframes\n",
    "df_list = []\n",
    "\n",
    "# Iterate through the dictionary and append ID to each dataframe\n",
    "for key, df in cgm_data_dict.items():\n",
    "    df[\"subject_id\"] = key  # Add a column with the key as the ID\n",
    "    df_list.append(df)  # Append to the list\n",
    "\n",
    "# Concatenate all dataframes\n",
    "combined_df_cgm = pd.concat(df_list, axis=0)\n",
    "\n",
    "# Reset index for the combined dataframe\n",
    "combined_df_cgm.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(combined_df_cgm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a7d74-fa2e-4e44-bc3d-7dd150469bf7",
   "metadata": {
    "id": "eb5a7d74-fa2e-4e44-bc3d-7dd150469bf7",
    "outputId": "f5380e82-2fe5-4b6e-b428-9bbebc32fbb5"
   },
   "outputs": [],
   "source": [
    "plt.savefig(f'{sub_id}_glucose_windows.png', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8165b78b-c069-4a18-b1be-b0bb12e712d2",
   "metadata": {
    "id": "8165b78b-c069-4a18-b1be-b0bb12e712d2",
    "outputId": "2e411c93-9091-4959-da1a-66c8d313d826"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# NOTEBOOK 3 EXAMPLE CODE\n",
    "#############################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "\n",
    "# If diametrics is not in PYTHONPATH, you might need a local install or sys.path\n",
    "# from diametrics import metrics, preprocessing\n",
    "\n",
    "#############################################\n",
    "# 1) LOAD PROTEOMICS DATA\n",
    "#############################################\n",
    "\n",
    "proteomics_path = r\"../../../proteomics_data_analysis_task/raw_data/proteomics_data/df_data_proteomics_olink_running_proteins_plate2a.csv\"\n",
    "df_prot = pd.read_csv(proteomics_path)\n",
    "\n",
    "print(\"Proteomics data loaded. Columns:\", df_prot.columns.to_list())\n",
    "print(df_prot.head(3))\n",
    "\n",
    "# We assume this has columns like:\n",
    "#   subject_id, group, timepoint, Assay, NPX\n",
    "# Possibly 1070 unique Assay values, timepoints in {R-1, R, R+1, R+7}, etc.\n",
    "\n",
    "#############################################\n",
    "# 2) LOAD CGM DATA + WORKOUT METADATA\n",
    "#############################################\n",
    "\n",
    "#cgm_path = \"cgm_data.csv\"\n",
    "#df_cgm = pd.read_csv(cgm_path)\n",
    "df_cgm = combined_df_cgm\n",
    "df_cgm['time'] = pd.to_datetime(df_cgm['time'])\n",
    "\n",
    "meta_path = \"../../../proteomics_data_analysis_task/raw_data/demographic_metadata.csv\"\n",
    "df_meta = pd.read_csv(meta_path)\n",
    "df_meta['workout_start'] = pd.to_datetime(df_meta['workout_start'])\n",
    "df_meta['workout_end']   = pd.to_datetime(df_meta['workout_end'])\n",
    "\n",
    "print(\"\\nCGM data columns:\", df_cgm.columns)\n",
    "print(\"Metadata columns:\", df_meta.columns)\n",
    "\n",
    "#############################################\n",
    "# 3) EXTRACT ~36 HRS OF CGM & PLOT WITH SHADING\n",
    "#############################################\n",
    "\n",
    "def extract_cgm_window(df, start_dt, hours=36):\n",
    "    \"\"\"\n",
    "    Takes a CGM DataFrame (df) with a 'time' column,\n",
    "    extracts from 'start_dt' to start_dt + 'hours' hours.\n",
    "    \"\"\"\n",
    "    end_dt = start_dt + timedelta(hours=hours)\n",
    "    subset = df[(df['time'] >= start_dt) & (df['time'] <= end_dt)].copy()\n",
    "    return subset\n",
    "\n",
    "def plot_glucose_trace(df, workout_start, workout_end, subject_id=None):\n",
    "    \"\"\"\n",
    "    Plot time vs. glc from df, shading workout & sleep intervals.\n",
    "    subject_id is optional, just for the title/label if needed.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10,4))\n",
    "\n",
    "    ax.plot(df['time'], df['glc'], color='blue', label='Glucose Trace')\n",
    "\n",
    "    # Shade workout\n",
    "    ax.axvspan(workout_start, workout_end, alpha=0.3, color='red', label='Workout')\n",
    "\n",
    "    # Assume typical sleep: 22:00 -> 06:00\n",
    "    # We'll do it for the first night only (if needed).\n",
    "    day_of_workout = workout_start.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    sleep_start = day_of_workout + pd.Timedelta(hours=22)\n",
    "    sleep_end   = day_of_workout + pd.Timedelta(hours=30)  # next day 6am\n",
    "    ax.axvspan(sleep_start, sleep_end, alpha=0.1, color='gray', label='Sleep')\n",
    "\n",
    "    title_txt = f\"Glucose Trace (Subject: {subject_id})\" if subject_id else \"Glucose Trace\"\n",
    "    ax.set_title(title_txt, fontsize=14)\n",
    "    ax.set_xlabel(\"Time\", fontsize=12)\n",
    "    ax.set_ylabel(\"Glucose\", fontsize=12)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#############################################\n",
    "# 4) COMPUTE CGM METRICS (EXAMPLE USING DIAMETRICS)\n",
    "#############################################\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./diametrics/\")\n",
    "from src.diametrics import transform, metrics, preprocessing, visualizations\n",
    "\n",
    "\n",
    "def compute_glycemic_metrics(df):\n",
    "    \"\"\"\n",
    "    Example wrapper: if you're using diametrics,\n",
    "    df should have columns: time, glc, maybe subject_id.\n",
    "    \"\"\"\n",
    "    # If needed, detect or change units\n",
    "    units = preprocessing.detect_units(df)\n",
    "    df = preprocessing.change_units(df)  # if you must unify mg/dL vs. mmol\n",
    "\n",
    "    # We'll do an example call to all_standard_metrics\n",
    "    # This returns a DF with various columns (start_dt, end_dt, avg_glc, etc.)\n",
    "    # if 'ID' not in df.columns, we can treat as single subject by ignoring grouping\n",
    "    # or set df['ID'] = 'single_subject'\n",
    "    # df['ID'] = df.get('ID', 'dummy_subject')\n",
    "\n",
    "    cgm_metrics_df = metrics.all_standard_metrics(df, units=None, gap_size=5)\n",
    "    return cgm_metrics_df\n",
    "\n",
    "    # For demonstration if diametrics not installed, return a dummy DF:\n",
    "    return pd.DataFrame({\n",
    "        'subject_id': [df['subject_id'].iloc[0] if 'subject_id' in df.columns else 'unknown'],\n",
    "        'avg_glc': [df['glc'].mean()],\n",
    "        'mage': [df['glc'].std()*1.5],  # not real MAGE calc, just a placeholder\n",
    "        'time_in_range': [80.0]        # dummy\n",
    "    })\n",
    "\n",
    "#############################################\n",
    "# 5) MERGE PROTEOMICS + CGM METRICS + DO REGRESSION\n",
    "#############################################\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def regression_proteins_to_cgm(df_proteomics, df_cgm_metrics):\n",
    "    \"\"\"\n",
    "    Example:\n",
    "      - df_proteomics has columns like [subject_id, group, timepoint, Assay, NPX].\n",
    "      - df_cgm_metrics has [subject_id, avg_glc, mage, time_in_range, etc.].\n",
    "    We'll do a simple pivot on df_proteomics to get each subject's average NPX\n",
    "    for each protein or timepoint, then merge with df_cgm_metrics on subject_id.\n",
    "    Then run a LinearRegression for demonstration.\n",
    "    \"\"\"\n",
    "    # 5a) Pivot proteomics: subject_id => row, (Assay) => columns\n",
    "    # We'll pick a single timepoint, or average across R-1, R, ...\n",
    "    # For demonstration, let's pick R-1 (pre-workout) as the features\n",
    "    prot_rminus1 = df_proteomics[df_proteomics['timepoint'] == 'R-1'].copy()\n",
    "    if prot_rminus1.empty:\n",
    "        print(\"No data at R-1 for proteomics. Skipping regression.\")\n",
    "        return\n",
    "\n",
    "    pivot_df = prot_rminus1.pivot_table(\n",
    "        index='subject_id',\n",
    "        columns='Assay',\n",
    "        values='NPX',\n",
    "        aggfunc='mean'  # if multiple rows per subject/assay\n",
    "    ).reset_index()\n",
    "\n",
    "    # 5b) Merge with cgm_metrics on subject_id\n",
    "    merged = pd.merge(pivot_df, df_cgm_metrics, on='subject_id', how='inner')\n",
    "    print(\"Merged shape:\", merged.shape)\n",
    "\n",
    "    # Suppose we want to predict avg_glc from all protein columns\n",
    "    # We'll find columns that are the proteomics assays\n",
    "    protein_cols = prot_rminus1['Assay'].unique().tolist()\n",
    "    # remove any that appear in df_cgm_metrics\n",
    "    Xcols = [col for col in protein_cols if col in merged.columns]\n",
    "\n",
    "    # define X and y\n",
    "    X = merged[Xcols].fillna(0).values  # naive fill for missing\n",
    "    y = merged['mage'].values # replace with column for other features as desired\n",
    "\n",
    "    if len(X) < 2:\n",
    "        print(\"Not enough data for regression.\")\n",
    "        return\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    r2 = model.score(X, y)\n",
    "    print(\"LinearRegression R^2 for avg_glc:\", r2)\n",
    "\n",
    "    # Show top coefficients (if many proteins, this is large)\n",
    "    for protein, coef in zip(Xcols, model.coef_):\n",
    "        print(f\"{protein}: {coef:.3f}\")\n",
    "\n",
    "    df_protein_coef = pd.DataFrame([])\n",
    "    df_protein_coef['Protein'] = Xcols\n",
    "    df_protein_coef['coef'] = model.coef_\n",
    "\n",
    "    model_intercept = model.intercept_\n",
    "\n",
    "    return model, df_protein_coef\n",
    "\n",
    "#############################################\n",
    "# MAIN LOGIC: DEMONSTRATION\n",
    "#############################################\n",
    "if __name__ == \"__main__\":\n",
    "    cgm_metrics_storage = []\n",
    "\n",
    "    # Loop over each subject in metadata\n",
    "    for idx, row in df_meta.iterrows():\n",
    "        subj_id = row['subject_id']\n",
    "        wstart = row['workout_start']\n",
    "        wend   = row['workout_end']\n",
    "\n",
    "        # Extract that subject's CGM from df_cgm\n",
    "        cgm_subj = df_cgm[df_cgm['subject_id'] == subj_id].copy()\n",
    "        if cgm_subj.empty:\n",
    "            print(f\"No CGM data for subject {subj_id}\")\n",
    "            continue\n",
    "\n",
    "        # We'll define the start for the 36-hour window as midnight of workout day\n",
    "        midn_before = wstart.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "        cgm_window = extract_cgm_window(cgm_subj, start_dt=midn_before, hours=36)\n",
    "        if cgm_window.empty:\n",
    "            print(f\"No CGM readings in the 36-hr window for {subj_id}\")\n",
    "            continue\n",
    "\n",
    "        # Plot\n",
    "        plot_glucose_trace(cgm_window, wstart, wend, subject_id=subj_id)\n",
    "\n",
    "        # Compute CGM metrics (example)\n",
    "        # Optionally add 'subject_id' column so metrics can be merged\n",
    "        cgm_window['subject_id'] = subj_id\n",
    "        metrics_df = compute_glycemic_metrics(cgm_window)\n",
    "        metrics_df['subject_id']=subj_id\n",
    "        print(f\"Computed metrics for subj {subj_id}:\\n\", metrics_df)\n",
    "\n",
    "        # Collect results in a list to merge later\n",
    "        cgm_metrics_storage.append(metrics_df)\n",
    "\n",
    "    # Combine all subjects' CGM metrics\n",
    "    if len(cgm_metrics_storage) > 0:\n",
    "        cgm_all_metrics = pd.concat(cgm_metrics_storage, ignore_index=True)\n",
    "    else:\n",
    "        cgm_all_metrics = pd.DataFrame()\n",
    "\n",
    "    print(\"\\nAll subject CGM metrics:\\n\", cgm_all_metrics)\n",
    "\n",
    "    # Finally, run regression: proteomics -> CGM metrics\n",
    "    # We'll use our df_prot (proteomics) and the cgm_all_metrics\n",
    "    if not cgm_all_metrics.empty:\n",
    "        model, df_protein_coefs = regression_proteins_to_cgm(df_prot, cgm_all_metrics)\n",
    "        # This tries to predict 'avg_glc' from NPX (R-1) in proteomics\n",
    "    else:\n",
    "        print(\"No CGM metrics available, skipping regression.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a297e4ce-4950-4048-9246-612392782288",
   "metadata": {
    "id": "a297e4ce-4950-4048-9246-612392782288",
    "outputId": "6a49ae0e-9496-4712-d096-a9a13c4ac955"
   },
   "outputs": [],
   "source": [
    "df_protein_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f1bf30-3ee7-492e-afb3-71eb2aec93d1",
   "metadata": {
    "id": "71f1bf30-3ee7-492e-afb3-71eb2aec93d1",
    "outputId": "009e60fb-01b5-42b5-de6d-72523352e852"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df_protein_coefs is already defined\n",
    "# Sort dataframe by 'coef' in descending order\n",
    "df_sorted = df_protein_coefs.sort_values(by=\"coef\", ascending=False)\n",
    "\n",
    "# Create the horizontal bar chart\n",
    "plt.figure(figsize=(12, 150))\n",
    "plt.barh(df_sorted[\"Protein\"], df_sorted[\"coef\"], color='blue', alpha=0.7)\n",
    "plt.ylabel(\"Protein\", fontsize=12)\n",
    "plt.xlabel(\"Coefficient\", fontsize=12)\n",
    "plt.title(\"Protein Coefficients Sorted by Largest Value\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92286dc-3361-4261-b014-371508b8a718",
   "metadata": {
    "id": "b92286dc-3361-4261-b014-371508b8a718"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
